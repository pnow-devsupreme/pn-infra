{{- if .Values.global.hooks.healthChecks.rookCeph }}
---
# Rook-Ceph Cluster Health Check Hook
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.global.name | default .Release.Name }}-rook-ceph-health-check
  namespace: {{ .Values.global.targetNamespace | default "argocd" }}
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    argocd.argoproj.io/sync-wave: "2"
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      serviceAccountName: argocd-server
      containers:
      - name: ceph-health-checker
        image: bitnami/kubectl:latest
        command:
        - sh
        - -c
        - |
          set -e
          echo "üóÑÔ∏è Validating Rook-Ceph cluster health..."
          
          # Wait for rook-ceph namespace
          echo "Checking rook-ceph namespace..."
          kubectl wait --for=condition=Active namespace/rook-ceph --timeout=60s 2>/dev/null || {
            echo "‚ö†Ô∏è rook-ceph namespace not found, skipping Ceph health check"
            exit 0
          }
          
          # Wait for Rook operator to be ready
          echo "Waiting for Rook-Ceph operator..."
          kubectl wait --for=condition=Available deployment/rook-ceph-operator -n rook-ceph --timeout=300s
          echo "‚úÖ Rook-Ceph operator is ready"
          
          # Check if CephCluster exists
          if ! kubectl get cephcluster -n rook-ceph >/dev/null 2>&1; then
            echo "‚ö†Ô∏è No CephCluster found, skipping cluster health checks"
            echo "‚úÖ Rook-Ceph operator deployed successfully"
            exit 0
          fi
          
          CEPH_CLUSTER_NAME=$(kubectl get cephcluster -n rook-ceph -o name | head -1 | cut -d'/' -f2)
          echo "Found Ceph cluster: $CEPH_CLUSTER_NAME"
          
          # Wait for Ceph cluster to be ready (up to 10 minutes)
          echo "Waiting for Ceph cluster to be ready..."
          TIMEOUT=600
          START_TIME=$(date +%s)
          
          while true; do
            CURRENT_TIME=$(date +%s)
            ELAPSED=$((CURRENT_TIME - START_TIME))
            
            if [ $ELAPSED -gt $TIMEOUT ]; then
              echo "‚ùå Timeout waiting for Ceph cluster to be ready"
              kubectl get cephcluster $CEPH_CLUSTER_NAME -n rook-ceph -o yaml
              exit 1
            fi
            
            CLUSTER_PHASE=$(kubectl get cephcluster $CEPH_CLUSTER_NAME -n rook-ceph -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
            CLUSTER_STATE=$(kubectl get cephcluster $CEPH_CLUSTER_NAME -n rook-ceph -o jsonpath='{.status.state}' 2>/dev/null || echo "Unknown")
            
            echo "Cluster phase: $CLUSTER_PHASE, state: $CLUSTER_STATE"
            
            if [ "$CLUSTER_PHASE" = "Ready" ] && [ "$CLUSTER_STATE" = "Created" ]; then
              echo "‚úÖ Ceph cluster is ready"
              break
            elif [ "$CLUSTER_PHASE" = "Progressing" ] || [ "$CLUSTER_STATE" = "Creating" ]; then
              echo "‚è≥ Cluster still initializing... (${ELAPSED}s elapsed)"
              sleep 30
            else
              echo "‚ö†Ô∏è Unexpected cluster state: phase=$CLUSTER_PHASE, state=$CLUSTER_STATE"
              sleep 30
            fi
          done
          
          # Wait for Mon quorum
          echo "Checking Mon quorum..."
          kubectl wait --for=condition=Ready pod -l app=rook-ceph-mon -n rook-ceph --timeout=300s
          
          MON_COUNT=$(kubectl get pods -n rook-ceph -l app=rook-ceph-mon --no-headers | grep -c Running || echo "0")
          echo "‚úÖ Ceph Mon quorum established ($MON_COUNT monitors running)"
          
          # Wait for OSDs
          echo "Checking OSDs..."
          sleep 30  # Give OSDs time to start
          OSD_COUNT=$(kubectl get pods -n rook-ceph -l app=rook-ceph-osd --no-headers | grep -c Running || echo "0")
          if [ $OSD_COUNT -gt 0 ]; then
            echo "‚úÖ Ceph OSDs running ($OSD_COUNT OSDs)"
          else
            echo "‚ö†Ô∏è No OSDs found - storage may not be fully functional"
          fi
          
          # Check MGR
          MGR_COUNT=$(kubectl get pods -n rook-ceph -l app=rook-ceph-mgr --no-headers | grep -c Running || echo "0")
          if [ $MGR_COUNT -gt 0 ]; then
            echo "‚úÖ Ceph MGR running ($MGR_COUNT managers)"
          else
            echo "‚ö†Ô∏è No MGR pods found"
          fi
          
          # Validate storage classes
          echo "Checking Ceph storage classes..."
          RBD_SC=$(kubectl get storageclass rook-ceph-block -o name 2>/dev/null || echo "")
          CEPHFS_SC=$(kubectl get storageclass rook-cephfs -o name 2>/dev/null || echo "")
          
          if [ -n "$RBD_SC" ]; then
            echo "‚úÖ RBD storage class available"
          else
            echo "‚ö†Ô∏è RBD storage class not found"
          fi
          
          if [ -n "$CEPHFS_SC" ]; then
            echo "‚úÖ CephFS storage class available"
          else
            echo "‚ö†Ô∏è CephFS storage class not found"
          fi
          
          echo ""
          echo "üéâ Rook-Ceph validation completed!"
          echo ""
          echo "üìã CLUSTER SUMMARY:"
          echo "‚Ä¢ Monitors: $MON_COUNT running"
          echo "‚Ä¢ OSDs: $OSD_COUNT running"  
          echo "‚Ä¢ Managers: $MGR_COUNT running"
          echo ""
          
      restartPolicy: Never
  backoffLimit: 3
{{- end }}